{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = [\n",
    "    'Adventure',\n",
    "    'AirRaid',\n",
    "    'Alien',\n",
    "    'Amidar',\n",
    "    'Assault',\n",
    "    'Asterix',\n",
    "    'Asteroids',\n",
    "    'Atlantis',\n",
    "    'Atlantis2',\n",
    "    'Backgammon',\n",
    "    'BankHeist',\n",
    "    'BasicMath',\n",
    "    'BattleZone',\n",
    "    'BeamRider',\n",
    "    'Berzerk',\n",
    "    'Blackjack',\n",
    "    'Bowling',\n",
    "    'Boxing',\n",
    "    'Breakout',\n",
    "    'CMakeLists',\n",
    "    'Carnival',\n",
    "    'Casino',\n",
    "    'Centipede',\n",
    "    'ChopperCommand',\n",
    "    'CrazyClimber',\n",
    "    'Crossbow',\n",
    "    'DarkChambers',\n",
    "    'Defender',\n",
    "    'DemonAttack',\n",
    "    'DonkeyKong',\n",
    "    'DoubleDunk',\n",
    "    'Earthworld',\n",
    "    'ElevatorAction',\n",
    "    'Enduro',\n",
    "    'Entombed',\n",
    "    'Et',\n",
    "    'FishingDerby',\n",
    "    'FlagCapture',\n",
    "    'Freeway',\n",
    "    'Frogger',\n",
    "    'Frostbite',\n",
    "    'Galaxian',\n",
    "    'Gopher',\n",
    "    'Gravitar',\n",
    "    'Hangman',\n",
    "    'HauntedHouse',\n",
    "    'Hero',\n",
    "    'HumanCannonball',\n",
    "    'IceHockey',\n",
    "    'JamesBond',\n",
    "    'JourneyEscape',\n",
    "    'Kaboom',\n",
    "    'Kangaroo',\n",
    "    'KeystoneKapers',\n",
    "    'Kingkong',\n",
    "    'Klax',\n",
    "    'Koolaid',\n",
    "    'Krull',\n",
    "    'KungFuMaster',\n",
    "    'LaserGates',\n",
    "    'LostLuggage',\n",
    "    'MarioBros',\n",
    "    'MiniatureGolf',\n",
    "    'MontezumaRevenge',\n",
    "    'MrDo',\n",
    "    'MsPacman',\n",
    "    'NameThisGame',\n",
    "    'Othello',\n",
    "    'Pacman',\n",
    "    'Phoenix',\n",
    "    'Pitfall',\n",
    "    'Pitfall2',\n",
    "    'Pong',\n",
    "    'Pooyan',\n",
    "    'PrivateEye',\n",
    "    'QBert',\n",
    "    'RiverRaid',\n",
    "    'RoadRunner',\n",
    "    'RoboTank',\n",
    "    'Seaquest',\n",
    "    'SirLancelot',\n",
    "    'Skiing',\n",
    "    'Solaris',\n",
    "    'SpaceInvaders',\n",
    "    'SpaceWar',\n",
    "    'StarGunner',\n",
    "    'Superman',\n",
    "    'Surround',\n",
    "    'Tennis',\n",
    "    'Tetris',\n",
    "    'TicTacToe3d',\n",
    "    'TimePilot',\n",
    "    'Trondead',\n",
    "    'Turmoil',\n",
    "    'Tutankham',\n",
    "    'UpNDown',\n",
    "    'Venture',\n",
    "    'VideoCheckers',\n",
    "    'VideoChess',\n",
    "    'VideoCube',\n",
    "    'VideoPinball',\n",
    "    'WizardOfWor',\n",
    "    'WordZapper',\n",
    "    'YarsRevenge',\n",
    "    'Zaxxon'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = [\n",
    "    'Pong',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "seed = 0\n",
    "env_names = [\n",
    "    f\"ALE/{name}-v5\"\n",
    "    for name in available\n",
    "]\n",
    "envs = {}\n",
    "i = 0\n",
    "for name in env_names:\n",
    "    try:\n",
    "        envs[f'{name}_{i}'] = gym.make(name)\n",
    "    except:\n",
    "        try:\n",
    "            envs[f'{name}_{i}'] = gym.make(name.capitalize())\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (210, 160, 3)\n",
    "exclude_env = []\n",
    "observation = None\n",
    "for env_name, env in envs.items():\n",
    "    observation, _ = env.reset(seed=seed)\n",
    "    if observation.shape != input_shape:\n",
    "        exclude_env.append(env_name)\n",
    "        continue\n",
    "    \n",
    "for env_name in exclude_env:\n",
    "    del envs[env_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = f'Atari_85_games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atari_85_games_autoencoder_0.4.state_dict'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name = f\"{all_names}_autoencoder_{encoder_alpha}.state_dict\"\n",
    "weights_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 40, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "def resize_frame(frame):\n",
    "    image_resized = downscale_local_mean(frame, (6, 4, 1))\n",
    "    return image_resized.astype(int)\n",
    "    \n",
    "image_downscaled = resize_frame(observation)\n",
    "input_shape = image_downscaled.shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2bdf9ed40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_downscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('atari-autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocess_mean': 2.9275974254729795e-05,\n",
       " 'preprocess_std': 0.017280908223757496}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "preprocess_constants = joblib.load('preprocess_constants.joblib')\n",
    "preprocess_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from skimage.transform import downscale_local_mean\n",
    "\n",
    "\n",
    "class AtariEncoder(nn.Module):\n",
    "    conv_num_filters = 64\n",
    "    filter_size = 3\n",
    "    pool_size = 2\n",
    "    encode_size = 128\n",
    "    dense_mid_size = 512\n",
    "    bottleneck_size = (4, 5)\n",
    "    def __init__(self, debug=False):\n",
    "        super(AtariEncoder, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.conv_num_filters * self.bottleneck_size[0] * self.bottleneck_size[1], self.dense_mid_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.dense_mid_size, self.encode_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.movedim(-1, 1)\n",
    "        for layer in self.encoder.children():\n",
    "            x = layer(x)\n",
    "            if self.debug:\n",
    "                print(x.shape)\n",
    "        return x\n",
    "\n",
    "class AtariEncodingEnv(gym.ObservationWrapper):\n",
    "    def __init__(self, env, encoder, resize_shape, alpha, preprocess_mean, preprocess_std, device='cpu'):\n",
    "        super().__init__(env)\n",
    "        self.resize_shape = resize_shape\n",
    "        self.alpha = alpha\n",
    "        self.encoder = encoder\n",
    "        self.preprocess_mean = preprocess_mean\n",
    "        self.preprocess_std = preprocess_std\n",
    "        self.delta = None\n",
    "        self.device = device\n",
    "        self.observation_space = gym.spaces.box.Box(0, 1024, (128,), np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.resize_frame(observation)\n",
    "        if self.delta is None:\n",
    "            self.delta = np.zeros(observation.shape)\n",
    "        else:\n",
    "            delta_now = observation / 255.0 - self.delta / 255.0\n",
    "            self.delta = self.alpha * delta_now + (1 - self.alpha) * self.delta\n",
    "\n",
    "        if self.preprocess_mean is None:\n",
    "            self.preprocess_mean = np.mean(self.delta)\n",
    "        if self.preprocess_std is None:\n",
    "            self.preprocess_std = np.std(self.delta)\n",
    "\n",
    "        delta_normalized = self.preprocess_images(self.delta, self.preprocess_mean, self.preprocess_std)\n",
    "        \n",
    "        # Encoding the delta\n",
    "        delta_tensor = torch.tensor(delta_normalized, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        encoded = self.encoder(delta_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.delta = None\n",
    "        observation, info = self.env.reset(**kwargs)\n",
    "        return self.observation(observation), info\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, done, is_truncated, info = self.env.step(action)\n",
    "        return self.observation(observation), reward, done, is_truncated, info\n",
    "\n",
    "    def resize_frame(self, frame):\n",
    "        # resizing image with downscale_local_mean\n",
    "        return downscale_local_mean(frame, self.resize_shape).astype(int)\n",
    "\n",
    "    def preprocess_images(self, images, mean, std):\n",
    "        return (images - mean) / std\n",
    "\n",
    "    def load_encoder_weights(self, weights_path):\n",
    "        state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "        state_dict = {\n",
    "            k: v for k, v in state_dict.items() if k in self.encoder.state_dict()\n",
    "        }\n",
    "        self.encoder.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to initialize SDL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m vdisplay\u001b[39m.\u001b[39mstart()\n\u001b[1;32m      6\u001b[0m env_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mALE/Pong-ram-v5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(env_id, render_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhuman\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39mobservation_space)\n\u001b[1;32m      9\u001b[0m observation, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset(seed\u001b[39m=\u001b[39mseed)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/envs/registration.py:801\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m     render_mode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 801\u001b[0m     env \u001b[39m=\u001b[39m env_creator(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49menv_spec_kwargs)\n\u001b[1;32m    802\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    803\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    804\u001b[0m         \u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mgot an unexpected keyword argument \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrender_mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    805\u001b[0m         \u001b[39mand\u001b[39;00m apply_human_rendering\n\u001b[1;32m    806\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py:171\u001b[0m, in \u001b[0;36mAtariEnv.__init__\u001b[0;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, max_num_frames_per_episode, render_mode)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39male\u001b[39m.\u001b[39msetBool(\u001b[39m\"\u001b[39m\u001b[39msound\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[39m# Seed + Load\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed()\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m full_action_space:\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_set \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39male\u001b[39m.\u001b[39mgetLegalActionSet()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py:225\u001b[0m, in \u001b[0;36mAtariEnv.seed\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(roms, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_game):\n\u001b[1;32m    216\u001b[0m     \u001b[39mraise\u001b[39;00m Error(\n\u001b[1;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWe\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mre Unable to find the game \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_game\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. Note: Gymnasium no longer distributes ROMs. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf you own a license to use the necessary ROMs for research purposes you can download them \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 225\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49male\u001b[39m.\u001b[39;49mloadROM(\u001b[39mgetattr\u001b[39;49m(roms, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_game))\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_game_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39male\u001b[39m.\u001b[39msetMode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_game_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to initialize SDL"
     ]
    }
   ],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "\n",
    "vdisplay = Xvfb()\n",
    "vdisplay.start()\n",
    "\n",
    "env_id = \"ALE/Pong-ram-v5\"\n",
    "env = gym.make(env_id, render_mode=\"human\")\n",
    "print(env.observation_space)\n",
    "observation, _ = env.reset(seed=seed)\n",
    "print(observation.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    observation, _, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(observation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (128,), uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "0.0 220.7072\n",
      "0.0 351.91135\n",
      "0.0 430.27332\n",
      "0.0 477.48508\n",
      "0.0 505.6481\n",
      "0.0 522.2413\n",
      "0.0 532.3907\n",
      "0.0 538.35046\n",
      "0.0 541.95905\n",
      "0.0 544.30975\n"
     ]
    }
   ],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "\n",
    "vdisplay = Xvfb()\n",
    "vdisplay.start()\n",
    "\n",
    "env_id = \"ALE/Pong-v5\"\n",
    "env = gym.make(env_id, render_mode=\"human\")\n",
    "env = AtariEncodingEnv(env, AtariEncoder(debug=False), (6, 4, 1), alpha=encoder_alpha, **preprocess_constants)\n",
    "env.load_encoder_weights(weights_name)\n",
    "observation, _ = env.reset(seed=seed)\n",
    "print(observation.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    observation, _, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(observation.min(), observation.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1024.0, (128,), float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 916      |\n",
      "|    ep_rew_mean     | -20.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 1626     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 14336    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -20.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 757          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073909587 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | -0.0359      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0169       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    value_loss           | 0.0644       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -20.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075024175 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0163       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 0.0571       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 947         |\n",
      "|    ep_rew_mean          | -20.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012344481 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0277      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 0.0607      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 960        |\n",
      "|    ep_rew_mean          | -20.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 606        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177582 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.76      |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0424     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.000647  |\n",
      "|    value_loss           | 0.094      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 977         |\n",
      "|    ep_rew_mean          | -20.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008928292 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 0.074       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 983         |\n",
      "|    ep_rew_mean          | -20.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011029853 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0219      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 0.0954      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -20.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 762          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077999504 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0293       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000335    |\n",
      "|    value_loss           | 0.0739       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -19.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 801          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070318733 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0578       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000414    |\n",
      "|    value_loss           | 0.0971       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -19.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 834          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066164634 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0588       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -4.58e-05    |\n",
      "|    value_loss           | 0.0855       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 864         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013396063 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.000725   |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -20         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012612411 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    value_loss           | 0.079       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -20         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010564342 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0661      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000828   |\n",
      "|    value_loss           | 0.0975      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 935         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010206854 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0532      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.000333    |\n",
      "|    value_loss           | 0.087       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 954         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012499833 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 0.092       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -19.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 972         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010549009 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 987         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010727246 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1002        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729597 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0305      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 0.0973      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1016        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009423733 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00492     |\n",
      "|    value_loss           | 0.0931      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.07e+03   |\n",
      "|    ep_rew_mean          | -19.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1028       |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 278        |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01175131 |\n",
      "|    clip_fraction        | 0.0488     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0736     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.000571  |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1040        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009774776 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0541      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00074    |\n",
      "|    value_loss           | 0.0937      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1051        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011521484 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0631      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 0.0966      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1061        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010375016 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1070        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008556937 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007932695 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -19.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1087         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 342          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115104895 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0961       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 0.0949       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947971 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 0.0957      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -19.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1102         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071648797 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0627       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000989    |\n",
      "|    value_loss           | 0.113        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1109        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010995279 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0453      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1115        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006416599 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1121        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008784985 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007930301 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000234   |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1131        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009164102 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0765      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.000255    |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1136        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020782491 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1141        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012649568 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0636      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1145        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008727235 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000868   |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1149        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010219166 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1153        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014184688 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0589      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -19.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1157         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 483          |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066202977 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0741       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000772    |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1160        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528824 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    value_loss           | 0.0986      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1163        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009736239 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.000824    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1167         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 515          |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066726645 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0759       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 0.105        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1170         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081673125 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0464       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 0.00047      |\n",
      "|    value_loss           | 0.113        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1172         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064102593 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0192       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 0.0945       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1175        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700048 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.000969    |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1178        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007767398 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.059       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1180        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013009337 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0504      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1183        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006695722 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000989   |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1185        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008343078 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00917    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.000116    |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1188        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006984518 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00086    |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -19.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1190       |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 614        |\n",
      "|    total_timesteps      | 731136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00747604 |\n",
      "|    clip_fraction        | 0.0373     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0428     |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.000242   |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1192         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 625          |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059590274 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.033        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000761    |\n",
      "|    value_loss           | 0.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1194         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 636          |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069532036 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0418       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.000224     |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -19.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1196        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006999962 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1198        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006488645 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 0.0963      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1200        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006266492 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1202         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 817152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077622114 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0448       |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 0.0971       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1203         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067102453 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0827       |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000483    |\n",
      "|    value_loss           | 0.119        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1205         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 701          |\n",
      "|    total_timesteps      | 845824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069468534 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0624       |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.000892    |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -19.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1206         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055878246 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0353       |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.000361     |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1208        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668689 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0224      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.000751   |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1209         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 734          |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044524297 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0798       |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1211        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006507691 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0711      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000172    |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1212        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 756         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009349625 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.073       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -19          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1214         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 767          |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067348024 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0599       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | 0.00118      |\n",
      "|    value_loss           | 0.128        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -19.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1215         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 778          |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096588675 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0359       |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000912    |\n",
      "|    value_loss           | 0.113        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -19.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1216        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 789         |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010480271 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0742      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.0205      |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -19          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1218         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 800          |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036569287 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0519       |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.00116      |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1219        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 811         |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022252789 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1220        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 822         |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021703776 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0621      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.0229      |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:217: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int = 0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: the environment ID\n",
    "    :param num_env: the number of environments you wish to have in subprocesses\n",
    "    :param seed: the inital seed for RNG\n",
    "    :param rank: index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return Monitor(env)\n",
    "    \n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_id = \"ALE/Pong-ram-v5\"\n",
    "    num_cpu = 7 # Number of processes to use\n",
    "    # Create the vectorized environment\n",
    "    vec_env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n",
    "\n",
    "    # Stable Baselines provides you with make_vec_env() helper\n",
    "    # which does exactly the previous steps for you.\n",
    "    # You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`\n",
    "    # env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "    model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "    model.learn(total_timesteps=1_000_000)\n",
    "\n",
    "    obs = vec_env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = vec_env.step(action)\n",
    "        vec_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 914      |\n",
      "|    ep_rew_mean     | -20.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 160      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 14336    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int = 0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: the environment ID\n",
    "    :param num_env: the number of environments you wish to have in subprocesses\n",
    "    :param seed: the inital seed for RNG\n",
    "    :param rank: index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env = AtariEncodingEnv(env, AtariEncoder(debug=False), (6, 4, 1), alpha=encoder_alpha, **preprocess_constants)\n",
    "        env.load_encoder_weights(weights_name)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return Monitor(env)\n",
    "    \n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_id = \"ALE/Pong-v5\"\n",
    "    num_cpu = 7 # Number of processes to use\n",
    "    # Create the vectorized environment\n",
    "    vec_env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n",
    "\n",
    "    # Stable Baselines provides you with make_vec_env() helper\n",
    "    # which does exactly the previous steps for you.\n",
    "    # You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`\n",
    "    # env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "    model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "    model.learn(total_timesteps=100_000_000)\n",
    "\n",
    "    obs = vec_env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = vec_env.step(action)\n",
    "        vec_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1. -1. -1. -1. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1. -1. -1.  0. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.  0.  0.  0.  0. -1.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1.  0. -1.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0. -1.  0.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.  0.  0. -1.  0.  0. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0. -1.  0.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkServerProcess-3:\n",
      "Process ForkServerProcess-2:\n",
      "Process ForkServerProcess-5:\n",
      "Process ForkServerProcess-7:\n",
      "Process ForkServerProcess-4:\n",
      "Process ForkServerProcess-6:\n",
      "Process ForkServerProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64020 requests (64020 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[0;32m----> 4\u001b[0m     obs, rewards, dones, info \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(rewards)\n\u001b[1;32m      6\u001b[0m     vec_env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:180\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:132\u001b[0m, in \u001b[0;36mSubprocVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 132\u001b[0m     results \u001b[39m=\u001b[39m [remote\u001b[39m.\u001b[39mrecv() \u001b[39mfor\u001b[39;00m remote \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes]\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     obs, rews, dones, infos, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:132\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 132\u001b[0m     results \u001b[39m=\u001b[39m [remote\u001b[39m.\u001b[39;49mrecv() \u001b[39mfor\u001b[39;00m remote \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes]\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     obs, rews, dones, infos, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    print(rewards)\n",
    "    vec_env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
