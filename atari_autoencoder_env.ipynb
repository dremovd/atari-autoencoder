{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = [\n",
    "    'Adventure',\n",
    "    'AirRaid',\n",
    "    'Alien',\n",
    "    'Amidar',\n",
    "    'Assault',\n",
    "    'Asterix',\n",
    "    'Asteroids',\n",
    "    'Atlantis',\n",
    "    'Atlantis2',\n",
    "    'Backgammon',\n",
    "    'BankHeist',\n",
    "    'BasicMath',\n",
    "    'BattleZone',\n",
    "    'BeamRider',\n",
    "    'Berzerk',\n",
    "    'Blackjack',\n",
    "    'Bowling',\n",
    "    'Boxing',\n",
    "    'Breakout',\n",
    "    'CMakeLists',\n",
    "    'Carnival',\n",
    "    'Casino',\n",
    "    'Centipede',\n",
    "    'ChopperCommand',\n",
    "    'CrazyClimber',\n",
    "    'Crossbow',\n",
    "    'DarkChambers',\n",
    "    'Defender',\n",
    "    'DemonAttack',\n",
    "    'DonkeyKong',\n",
    "    'DoubleDunk',\n",
    "    'Earthworld',\n",
    "    'ElevatorAction',\n",
    "    'Enduro',\n",
    "    'Entombed',\n",
    "    'Et',\n",
    "    'FishingDerby',\n",
    "    'FlagCapture',\n",
    "    'Freeway',\n",
    "    'Frogger',\n",
    "    'Frostbite',\n",
    "    'Galaxian',\n",
    "    'Gopher',\n",
    "    'Gravitar',\n",
    "    'Hangman',\n",
    "    'HauntedHouse',\n",
    "    'Hero',\n",
    "    'HumanCannonball',\n",
    "    'IceHockey',\n",
    "    'JamesBond',\n",
    "    'JourneyEscape',\n",
    "    'Kaboom',\n",
    "    'Kangaroo',\n",
    "    'KeystoneKapers',\n",
    "    'Kingkong',\n",
    "    'Klax',\n",
    "    'Koolaid',\n",
    "    'Krull',\n",
    "    'KungFuMaster',\n",
    "    'LaserGates',\n",
    "    'LostLuggage',\n",
    "    'MarioBros',\n",
    "    'MiniatureGolf',\n",
    "    'MontezumaRevenge',\n",
    "    'MrDo',\n",
    "    'MsPacman',\n",
    "    'NameThisGame',\n",
    "    'Othello',\n",
    "    'Pacman',\n",
    "    'Phoenix',\n",
    "    'Pitfall',\n",
    "    'Pitfall2',\n",
    "    'Pong',\n",
    "    'Pooyan',\n",
    "    'PrivateEye',\n",
    "    'QBert',\n",
    "    'RiverRaid',\n",
    "    'RoadRunner',\n",
    "    'RoboTank',\n",
    "    'Seaquest',\n",
    "    'SirLancelot',\n",
    "    'Skiing',\n",
    "    'Solaris',\n",
    "    'SpaceInvaders',\n",
    "    'SpaceWar',\n",
    "    'StarGunner',\n",
    "    'Superman',\n",
    "    'Surround',\n",
    "    'Tennis',\n",
    "    'Tetris',\n",
    "    'TicTacToe3d',\n",
    "    'TimePilot',\n",
    "    'Trondead',\n",
    "    'Turmoil',\n",
    "    'Tutankham',\n",
    "    'UpNDown',\n",
    "    'Venture',\n",
    "    'VideoCheckers',\n",
    "    'VideoChess',\n",
    "    'VideoCube',\n",
    "    'VideoPinball',\n",
    "    'WizardOfWor',\n",
    "    'WordZapper',\n",
    "    'YarsRevenge',\n",
    "    'Zaxxon'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Breakout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = [\n",
    "    name,\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "seed = 0\n",
    "env_names = [\n",
    "    f\"ALE/{name}-v5\"\n",
    "    for name in available\n",
    "]\n",
    "envs = {}\n",
    "i = 0\n",
    "for name in env_names:\n",
    "    try:\n",
    "        envs[f'{name}_{i}'] = gym.make(name)\n",
    "    except:\n",
    "        try:\n",
    "            envs[f'{name}_{i}'] = gym.make(name.capitalize())\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (210, 160, 3)\n",
    "exclude_env = []\n",
    "observation = None\n",
    "for env_name, env in envs.items():\n",
    "    observation, _ = env.reset(seed=seed)\n",
    "    if observation.shape != input_shape:\n",
    "        exclude_env.append(env_name)\n",
    "        continue\n",
    "    \n",
    "for env_name in exclude_env:\n",
    "    del envs[env_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = f'Atari_85_games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atari_85_games_autoencoder_0.4.state_dict'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name = f\"{all_names}_autoencoder_{encoder_alpha}.state_dict\"\n",
    "weights_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 40, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "def resize_frame(frame):\n",
    "    image_resized = downscale_local_mean(frame, (6, 4, 1))\n",
    "    return image_resized.astype(int)\n",
    "    \n",
    "image_downscaled = resize_frame(observation)\n",
    "input_shape = image_downscaled.shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f597e2dad10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_downscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('atari-autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocess_mean': 2.9275974254729795e-05,\n",
       " 'preprocess_std': 0.017280908223757496}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "preprocess_constants = joblib.load('preprocess_constants.joblib')\n",
    "preprocess_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from skimage.transform import downscale_local_mean\n",
    "\n",
    "\n",
    "class AtariEncoder(nn.Module):\n",
    "    conv_num_filters = 64\n",
    "    filter_size = 3\n",
    "    pool_size = 2\n",
    "    encode_size = 128\n",
    "    dense_mid_size = 512\n",
    "    bottleneck_size = (4, 5)\n",
    "    def __init__(self, debug=False):\n",
    "        super(AtariEncoder, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Conv2d(self.conv_num_filters, self.conv_num_filters, self.filter_size, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(self.pool_size, self.pool_size),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.conv_num_filters * self.bottleneck_size[0] * self.bottleneck_size[1], self.dense_mid_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.dense_mid_size, self.encode_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.movedim(-1, 1)\n",
    "        for layer in self.encoder.children():\n",
    "            x = layer(x)\n",
    "            if self.debug:\n",
    "                print(x.shape)\n",
    "        return x\n",
    "\n",
    "class AtariEncodingEnv(gym.ObservationWrapper):\n",
    "    def __init__(self, env, encoder, resize_shape, alpha, preprocess_mean, preprocess_std, device='cpu'):\n",
    "        super().__init__(env)\n",
    "        self.resize_shape = resize_shape\n",
    "        self.alpha = alpha\n",
    "        self.encoder = encoder\n",
    "        self.preprocess_mean = preprocess_mean\n",
    "        self.preprocess_std = preprocess_std\n",
    "        self.delta = None\n",
    "        self.device = device\n",
    "        self.observation_space = gym.spaces.box.Box(0, 1024, (128,), np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.resize_frame(observation)\n",
    "        if self.delta is None:\n",
    "            self.delta = np.zeros(observation.shape)\n",
    "        else:\n",
    "            delta_now = observation / 255.0 - self.delta / 255.0\n",
    "            self.delta = self.alpha * delta_now + (1 - self.alpha) * self.delta\n",
    "\n",
    "        if self.preprocess_mean is None:\n",
    "            self.preprocess_mean = np.mean(self.delta)\n",
    "        if self.preprocess_std is None:\n",
    "            self.preprocess_std = np.std(self.delta)\n",
    "\n",
    "        delta_normalized = self.preprocess_images(self.delta, self.preprocess_mean, self.preprocess_std)\n",
    "        \n",
    "        # Encoding the delta\n",
    "        delta_tensor = torch.tensor(delta_normalized, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        encoded = self.encoder(delta_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.delta = None\n",
    "        observation, info = self.env.reset(**kwargs)\n",
    "        return self.observation(observation), info\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, done, is_truncated, info = self.env.step(action)\n",
    "        return self.observation(observation), reward, done, is_truncated, info\n",
    "\n",
    "    def resize_frame(self, frame):\n",
    "        # resizing image with downscale_local_mean\n",
    "        return downscale_local_mean(frame, self.resize_shape).astype(int)\n",
    "\n",
    "    def preprocess_images(self, images, mean, std):\n",
    "        return (images - mean) / std\n",
    "\n",
    "    def load_encoder_weights(self, weights_path):\n",
    "        state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "        state_dict = {\n",
    "            k: v for k, v in state_dict.items() if k in self.encoder.state_dict()\n",
    "        }\n",
    "        self.encoder.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (128,), uint8)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "\n",
    "vdisplay = Xvfb()\n",
    "vdisplay.start()\n",
    "\n",
    "env_id = f\"ALE/{name}-ram-v5\"\n",
    "env = gym.make(env_id, render_mode=\"human\")\n",
    "print(env.observation_space)\n",
    "observation, _ = env.reset(seed=seed)\n",
    "print(observation.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    observation, _, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(observation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (128,), uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "0.0 190.21538\n",
      "0.0 301.1683\n",
      "0.0 367.40002\n",
      "0.0 408.10764\n",
      "0.0 433.33783\n",
      "0.0 449.27673\n",
      "0.0 458.03152\n",
      "0.0 460.90088\n",
      "0.0 462.7904\n",
      "0.0 464.12674\n"
     ]
    }
   ],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "\n",
    "vdisplay = Xvfb()\n",
    "vdisplay.start()\n",
    "\n",
    "env_id = f\"ALE/{name}-v5\"\n",
    "env = gym.make(env_id, render_mode=\"human\")\n",
    "env = AtariEncodingEnv(env, AtariEncoder(debug=False), (6, 4, 1), alpha=encoder_alpha, **preprocess_constants)\n",
    "env.load_encoder_weights(weights_name)\n",
    "observation, _ = env.reset(seed=seed)\n",
    "print(observation.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    observation, _, _, _, _ = env.step(env.action_space.sample())\n",
    "    print(observation.min(), observation.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1024.0, (128,), float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "Process ForkServerProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 33, in _worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m num_cpu \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m \u001b[39m# Number of processes to use\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# Create the vectorized environment\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m vec_env \u001b[39m=\u001b[39m SubprocVecEnv([make_env(env_id, i) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_cpu)])\n\u001b[1;32m     32\u001b[0m vec_env \u001b[39m=\u001b[39m VecFrameStack(vec_env, n_stack\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# Stable Baselines provides you with make_vec_env() helper\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# which does exactly the previous steps for you.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:120\u001b[0m, in \u001b[0;36mSubprocVecEnv.__init__\u001b[0;34m(self, env_fns, start_method)\u001b[0m\n\u001b[1;32m    117\u001b[0m     work_remote\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msend((\u001b[39m\"\u001b[39m\u001b[39mget_spaces\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 120\u001b[0m observation_space, action_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremotes[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msend((\u001b[39m\"\u001b[39m\u001b[39mget_attr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrender_mode\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    123\u001b[0m render_mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrecv()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int = 0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: the environment ID\n",
    "    :param num_env: the number of environments you wish to have in subprocesses\n",
    "    :param seed: the inital seed for RNG\n",
    "    :param rank: index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env = AtariEncodingEnv(env, AtariEncoder(debug=False), (6, 4, 1), alpha=encoder_alpha, **preprocess_constants)\n",
    "        env.load_encoder_weights(weights_name)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return Monitor(env)\n",
    "    \n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "env_id = f\"ALE/{name}-v5\"\n",
    "num_cpu = 7 # Number of processes to use\n",
    "# Create the vectorized environment\n",
    "vec_env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n",
    "vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "# Stable Baselines provides you with make_vec_env() helper\n",
    "# which does exactly the previous steps for you.\n",
    "# You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`\n",
    "# env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1, tensorboard_log=f\"{name}/encoder\")\n",
    "model.learn(total_timesteps=100_000_000)\n",
    "\n",
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to Breakout/ram/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 1.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 2199     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 14336    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 1.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1430        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008398772 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.317      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00658     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    value_loss           | 0.0302      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 1.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1272        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028139 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00486     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000307   |\n",
      "|    value_loss           | 0.0555      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 188        |\n",
      "|    ep_rew_mean          | 1.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1204       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01650409 |\n",
      "|    clip_fraction        | 0.0353     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.00325    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0582     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00231   |\n",
      "|    value_loss           | 0.0493     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 213         |\n",
      "|    ep_rew_mean          | 2.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1166        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009678616 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.00274     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 0.0548      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 229         |\n",
      "|    ep_rew_mean          | 2.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1142        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011018605 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.00242     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 0.0839      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | 3.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010619715 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.00189     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0169      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 3.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1117        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015261454 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.00202     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 255         |\n",
      "|    ep_rew_mean          | 4           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1109        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006151821 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.00147     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.000916   |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 254          |\n",
      "|    ep_rew_mean          | 3.99         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1101         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061049396 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.00149      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0553       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    value_loss           | 0.207        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 4.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1096        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379695 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.000917    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0249      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.000904   |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 4.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1092        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015161837 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0013      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0861      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 4.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004483632 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.00107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0616      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000468   |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 250         |\n",
      "|    ep_rew_mean          | 4.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1086        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017604101 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.00103     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 251          |\n",
      "|    ep_rew_mean          | 4.15         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1083         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097734975 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.00105      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.273        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 5.47e-05     |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 4.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004513078 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.00078     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | 4.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1078         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016123662 |\n",
      "|    clip_fraction        | 0.00525      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.000909     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.000246     |\n",
      "|    value_loss           | 0.271        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | 4.61         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1077         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056662075 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.989       |\n",
      "|    explained_variance   | 0.000717     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0619       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 0.207        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 262          |\n",
      "|    ep_rew_mean          | 4.85         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1075         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026263276 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | 0.000882     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000911    |\n",
      "|    value_loss           | 0.282        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 260          |\n",
      "|    ep_rew_mean          | 4.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1073         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 267          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035463774 |\n",
      "|    clip_fraction        | 0.00462      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.972       |\n",
      "|    explained_variance   | 0.00112      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.298        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.000344     |\n",
      "|    value_loss           | 0.286        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | 4.94         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1072         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015484047 |\n",
      "|    clip_fraction        | 0.00779      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.916       |\n",
      "|    explained_variance   | 0.000917     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.188        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | 0.000203     |\n",
      "|    value_loss           | 0.316        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 251         |\n",
      "|    ep_rew_mean          | 4.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1070        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006523906 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.967      |\n",
      "|    explained_variance   | 0.000914    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0859      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 246          |\n",
      "|    ep_rew_mean          | 4.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1068         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 308          |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063452637 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.000754     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.058        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 238         |\n",
      "|    ep_rew_mean          | 4.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1066        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003112474 |\n",
      "|    clip_fraction        | 0.00508     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.00105     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.000237    |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 235         |\n",
      "|    ep_rew_mean          | 4.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1065        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010195128 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.000951    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    value_loss           | 0.353       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 5.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1064        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006295945 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.864      |\n",
      "|    explained_variance   | 0.000612    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.000876   |\n",
      "|    value_loss           | 0.312       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 256          |\n",
      "|    ep_rew_mean          | 5.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1062         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035542047 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.859       |\n",
      "|    explained_variance   | 0.00094      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.203        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00051     |\n",
      "|    value_loss           | 0.38         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 252          |\n",
      "|    ep_rew_mean          | 5.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1060         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050535724 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.000695     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000434    |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 254          |\n",
      "|    ep_rew_mean          | 5.79         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1058         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034902047 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.699       |\n",
      "|    explained_variance   | 0.00111      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000849    |\n",
      "|    value_loss           | 0.39         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 5.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1056        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004103947 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.761      |\n",
      "|    explained_variance   | 0.00114     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 0.401       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 250        |\n",
      "|    ep_rew_mean          | 5.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1053       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 421        |\n",
      "|    total_timesteps      | 444416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00506073 |\n",
      "|    clip_fraction        | 0.00758    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.718     |\n",
      "|    explained_variance   | 0.00067    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.151      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 2.13e-05   |\n",
      "|    value_loss           | 0.334      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 245         |\n",
      "|    ep_rew_mean          | 4.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1050        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003308185 |\n",
      "|    clip_fraction        | 0.0065      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | 0.000905    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000149   |\n",
      "|    value_loss           | 0.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 238         |\n",
      "|    ep_rew_mean          | 4.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1047        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002668112 |\n",
      "|    clip_fraction        | 0.00398     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.000606    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.000188    |\n",
      "|    value_loss           | 0.345       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 234          |\n",
      "|    ep_rew_mean          | 4.17         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1045         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 466          |\n",
      "|    total_timesteps      | 487424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028915505 |\n",
      "|    clip_fraction        | 0.00559      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.737       |\n",
      "|    explained_variance   | 0.000542     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.308        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 5.14e-05     |\n",
      "|    value_loss           | 0.336        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 242           |\n",
      "|    ep_rew_mean          | 4.53          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1042          |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 481           |\n",
      "|    total_timesteps      | 501760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070508115 |\n",
      "|    clip_fraction        | 0.00532       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.71         |\n",
      "|    explained_variance   | 0.000297      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.061         |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | 0.000147      |\n",
      "|    value_loss           | 0.267         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 243         |\n",
      "|    ep_rew_mean          | 4.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1039        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004760745 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.00064     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000262   |\n",
      "|    value_loss           | 0.333       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | 4.91         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1036         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 511          |\n",
      "|    total_timesteps      | 530432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045501804 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.651       |\n",
      "|    explained_variance   | 0.000851     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000321    |\n",
      "|    value_loss           | 0.333        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 263          |\n",
      "|    ep_rew_mean          | 5.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1034         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 544768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023192023 |\n",
      "|    clip_fraction        | 0.00517      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.000799     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.19         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.000193     |\n",
      "|    value_loss           | 0.332        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 266          |\n",
      "|    ep_rew_mean          | 5.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1031         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031697883 |\n",
      "|    clip_fraction        | 0.00842      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.00104      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.071        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -9.12e-06    |\n",
      "|    value_loss           | 0.396        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 275          |\n",
      "|    ep_rew_mean          | 5.56         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1029         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 557          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019908308 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.000714     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.229        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000361    |\n",
      "|    value_loss           | 0.351        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 279           |\n",
      "|    ep_rew_mean          | 5.74          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1027          |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 572           |\n",
      "|    total_timesteps      | 587776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036254484 |\n",
      "|    clip_fraction        | 0.0021        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.475        |\n",
      "|    explained_variance   | 0.00079       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.117         |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | 0.000269      |\n",
      "|    value_loss           | 0.354         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 280          |\n",
      "|    ep_rew_mean          | 5.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1025         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 587          |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018512884 |\n",
      "|    clip_fraction        | 0.00887      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.000818     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.215        |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000429    |\n",
      "|    value_loss           | 0.379        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 278          |\n",
      "|    ep_rew_mean          | 5.18         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1023         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015701434 |\n",
      "|    clip_fraction        | 0.00838      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.000771     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.153        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000352    |\n",
      "|    value_loss           | 0.324        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 267           |\n",
      "|    ep_rew_mean          | 5.08          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1021          |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 617           |\n",
      "|    total_timesteps      | 630784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048131222 |\n",
      "|    clip_fraction        | 0.00256       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.484        |\n",
      "|    explained_variance   | 0.000713      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.122         |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | 0.000165      |\n",
      "|    value_loss           | 0.326         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 266          |\n",
      "|    ep_rew_mean          | 5.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1019         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 632          |\n",
      "|    total_timesteps      | 645120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011673665 |\n",
      "|    clip_fraction        | 0.00665      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.000658     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.256        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000108    |\n",
      "|    value_loss           | 0.364        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 5.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1017        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002217789 |\n",
      "|    clip_fraction        | 0.00377     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.000737    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00012     |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 262          |\n",
      "|    ep_rew_mean          | 5.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1015         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 663          |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007691112 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.000914     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.139        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000284    |\n",
      "|    value_loss           | 0.389        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | 4.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1014         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 678          |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015974743 |\n",
      "|    clip_fraction        | 0.00458      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.000908     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000115    |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 259          |\n",
      "|    ep_rew_mean          | 5.21         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1012         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 702464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009804623 |\n",
      "|    clip_fraction        | 0.00491      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.000637     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0719       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -4.39e-05    |\n",
      "|    value_loss           | 0.363        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 263          |\n",
      "|    ep_rew_mean          | 5.33         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1011         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 708          |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012681757 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.000708     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.14         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000303    |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 273          |\n",
      "|    ep_rew_mean          | 5.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1009         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 724          |\n",
      "|    total_timesteps      | 731136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022590929 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.000663     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.283        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000601    |\n",
      "|    value_loss           | 0.349        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 272          |\n",
      "|    ep_rew_mean          | 5.57         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1008         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 739          |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015410617 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.000803     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000506    |\n",
      "|    value_loss           | 0.363        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 271          |\n",
      "|    ep_rew_mean          | 5.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1007         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 754          |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022504304 |\n",
      "|    clip_fraction        | 0.00683      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.000808     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.231        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    value_loss           | 0.395        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 272          |\n",
      "|    ep_rew_mean          | 5.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1005         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 769          |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009985393 |\n",
      "|    clip_fraction        | 0.00769      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.000694     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.159        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00029     |\n",
      "|    value_loss           | 0.359        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 265         |\n",
      "|    ep_rew_mean          | 5.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1004        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001387308 |\n",
      "|    clip_fraction        | 0.00519     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.000796    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.000254   |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 265          |\n",
      "|    ep_rew_mean          | 5.39         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1003         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 800          |\n",
      "|    total_timesteps      | 802816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015287636 |\n",
      "|    clip_fraction        | 0.0096       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.000673     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.126        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.000511    |\n",
      "|    value_loss           | 0.386        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 259          |\n",
      "|    ep_rew_mean          | 5.27         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1002         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 815          |\n",
      "|    total_timesteps      | 817152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005537029 |\n",
      "|    clip_fraction        | 0.0028       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.000423     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.166        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 9.17e-05     |\n",
      "|    value_loss           | 0.343        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | 5.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1001         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 830          |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016777336 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.000668     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.154        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000407    |\n",
      "|    value_loss           | 0.376        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 276          |\n",
      "|    ep_rew_mean          | 6.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1000         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 845          |\n",
      "|    total_timesteps      | 845824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012795153 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.000915     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -8.74e-05    |\n",
      "|    value_loss           | 0.421        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 289          |\n",
      "|    ep_rew_mean          | 5.86         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 999          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 860          |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007096326 |\n",
      "|    clip_fraction        | 0.00418      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.331       |\n",
      "|    explained_variance   | 0.000685     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.213        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 2.17e-05     |\n",
      "|    value_loss           | 0.394        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 291          |\n",
      "|    ep_rew_mean          | 5.95         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 998          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 875          |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009060171 |\n",
      "|    clip_fraction        | 0.00743      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 0.000384     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000321    |\n",
      "|    value_loss           | 0.344        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 286          |\n",
      "|    ep_rew_mean          | 5.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 997          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 891          |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014361305 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0.000731     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.000419    |\n",
      "|    value_loss           | 0.407        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 285          |\n",
      "|    ep_rew_mean          | 5.48         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 996          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 906          |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010074609 |\n",
      "|    clip_fraction        | 0.00638      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 0.000468     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.143        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.000132    |\n",
      "|    value_loss           | 0.314        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 286           |\n",
      "|    ep_rew_mean          | 5.46          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 995           |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 921           |\n",
      "|    total_timesteps      | 917504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029819383 |\n",
      "|    clip_fraction        | 0.00232       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.338        |\n",
      "|    explained_variance   | 0.00058       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.118         |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | 4.02e-05      |\n",
      "|    value_loss           | 0.377         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 278          |\n",
      "|    ep_rew_mean          | 5.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 994          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 936          |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013140764 |\n",
      "|    clip_fraction        | 0.00901      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | 0.00027      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.148        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000368    |\n",
      "|    value_loss           | 0.307        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | 5.75         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 994          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 951          |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012627254 |\n",
      "|    clip_fraction        | 0.0067       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.000476     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.205        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    value_loss           | 0.334        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 270         |\n",
      "|    ep_rew_mean          | 5.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 993         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001367309 |\n",
      "|    clip_fraction        | 0.00578     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.000846    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.381       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.000181   |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 257         |\n",
      "|    ep_rew_mean          | 5.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 992         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001613719 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.000639    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000587   |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 256          |\n",
      "|    ep_rew_mean          | 5.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 991          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 997          |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023992807 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.000719     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0731       |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000493    |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 257          |\n",
      "|    ep_rew_mean          | 5.15         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 990          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 1012         |\n",
      "|    total_timesteps      | 1003520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009895844 |\n",
      "|    clip_fraction        | 0.00964      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.000771     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000441    |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 251           |\n",
      "|    ep_rew_mean          | 5.1           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 990           |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 1028          |\n",
      "|    total_timesteps      | 1017856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096695364 |\n",
      "|    clip_fraction        | 0.00914       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.437        |\n",
      "|    explained_variance   | 0.000632      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.156         |\n",
      "|    n_updates            | 700           |\n",
      "|    policy_gradient_loss | -0.000421     |\n",
      "|    value_loss           | 0.382         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | 5            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 989          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1043         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023202838 |\n",
      "|    clip_fraction        | 0.00955      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.000552     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0794       |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000256    |\n",
      "|    value_loss           | 0.344        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 253          |\n",
      "|    ep_rew_mean          | 5.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 988          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 1058         |\n",
      "|    total_timesteps      | 1046528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009230169 |\n",
      "|    clip_fraction        | 0.00599      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.000692     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -8.98e-05    |\n",
      "|    value_loss           | 0.365        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | 5.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 988          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1073         |\n",
      "|    total_timesteps      | 1060864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012195532 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.000761     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.135        |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000256     |\n",
      "|    value_loss           | 0.413        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 252          |\n",
      "|    ep_rew_mean          | 5.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 987          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1088         |\n",
      "|    total_timesteps      | 1075200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013797844 |\n",
      "|    clip_fraction        | 0.00963      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.000696     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.337        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.000571    |\n",
      "|    value_loss           | 0.384        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 247          |\n",
      "|    ep_rew_mean          | 5.17         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 986          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 1104         |\n",
      "|    total_timesteps      | 1089536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010737415 |\n",
      "|    clip_fraction        | 0.00432      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.000712     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.126        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.000109    |\n",
      "|    value_loss           | 0.394        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | 4.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 986          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 1119         |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022451873 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.000594     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.192        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -8.19e-05    |\n",
      "|    value_loss           | 0.346        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 254           |\n",
      "|    ep_rew_mean          | 5.42          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 985           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 1134          |\n",
      "|    total_timesteps      | 1118208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023416628 |\n",
      "|    clip_fraction        | 0.00337       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.000656      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.216         |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | 8.82e-05      |\n",
      "|    value_loss           | 0.366         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 256          |\n",
      "|    ep_rew_mean          | 5.46         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 984          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1149         |\n",
      "|    total_timesteps      | 1132544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033467743 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.000747     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0953       |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 265          |\n",
      "|    ep_rew_mean          | 5.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 984          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1165         |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013097312 |\n",
      "|    clip_fraction        | 0.00739      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.325       |\n",
      "|    explained_variance   | 0.00073      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.195        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000138    |\n",
      "|    value_loss           | 0.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 264          |\n",
      "|    ep_rew_mean          | 5.36         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 983          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 1180         |\n",
      "|    total_timesteps      | 1161216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011262987 |\n",
      "|    clip_fraction        | 0.00579      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.343       |\n",
      "|    explained_variance   | 0.000543     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.135        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00026     |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 263           |\n",
      "|    ep_rew_mean          | 5.47          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 983           |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 1195          |\n",
      "|    total_timesteps      | 1175552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094107335 |\n",
      "|    clip_fraction        | 0.00705       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.315        |\n",
      "|    explained_variance   | 0.000589      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.235         |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.000179     |\n",
      "|    value_loss           | 0.383         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 272          |\n",
      "|    ep_rew_mean          | 5.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 982          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1210         |\n",
      "|    total_timesteps      | 1189888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011222463 |\n",
      "|    clip_fraction        | 0.00656      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.345       |\n",
      "|    explained_variance   | 0.000543     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.443        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.000387    |\n",
      "|    value_loss           | 0.372        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int = 0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: the environment ID\n",
    "    :param num_env: the number of environments you wish to have in subprocesses\n",
    "    :param seed: the inital seed for RNG\n",
    "    :param rank: index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return Monitor(env)\n",
    "    \n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "env_id = f\"ALE/{name}-ram-v5\"\n",
    "num_cpu = 7 # Number of processes to use\n",
    "# Create the vectorized environment\n",
    "vec_env = SubprocVecEnv([make_env(env_id, i + 7) for i in range(num_cpu)])\n",
    "vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1, tensorboard_log=f\"{name}/ram\")\n",
    "model.learn(total_timesteps=10_000_000)\n",
    "\n",
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1. -1. -1. -1. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1. -1. -1.  0. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.  0.  0.  0.  0. -1.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1.  0. -1.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0. -1.  0.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[-1.  0. -1.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0.  0.  0. -1.  0.  0. -1.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 0. -1.  0.  0.  0.  0.  0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkServerProcess-3:\n",
      "Process ForkServerProcess-2:\n",
      "Process ForkServerProcess-5:\n",
      "Process ForkServerProcess-7:\n",
      "Process ForkServerProcess-4:\n",
      "Process ForkServerProcess-6:\n",
      "Process ForkServerProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\", line 35, in _worker\n",
      "    observation, reward, terminated, truncated, info = env.step(data)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/tmp/ipykernel_2804688/1050988659.py\", line 84, in step\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py\", line 56, in step\n",
      "    return self.env.step(action)\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py\", line 49, in step\n",
      "    return self.env.step(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/morph/anaconda3/envs/py310/lib/python3.10/site-packages/shimmy/atari_env.py\", line 294, in step\n",
      "    reward += self.ale.act(action)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n",
      "      after 64020 requests (64020 known processed) with 0 events remaining.\n",
      "XIO:  fatal IO error 0 (Success) on X server \":1185338903\"\n",
      "      after 64035 requests (64035 known processed) with 0 events remaining.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[0;32m----> 4\u001b[0m     obs, rewards, dones, info \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(rewards)\n\u001b[1;32m      6\u001b[0m     vec_env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:180\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 180\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:132\u001b[0m, in \u001b[0;36mSubprocVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 132\u001b[0m     results \u001b[39m=\u001b[39m [remote\u001b[39m.\u001b[39mrecv() \u001b[39mfor\u001b[39;00m remote \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes]\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     obs, rews, dones, infos, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py:132\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m--> 132\u001b[0m     results \u001b[39m=\u001b[39m [remote\u001b[39m.\u001b[39;49mrecv() \u001b[39mfor\u001b[39;00m remote \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes]\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwaiting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     obs, rews, dones, infos, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    print(rewards)\n",
    "    vec_env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
